{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2081,
     "status": "ok",
     "timestamp": 1637253835568,
     "user": {
      "displayName": "Axl Roland",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07744519565161145905"
     },
     "user_tz": -60
    },
    "id": "2D7T9bq7jvmp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import cv2\n",
    "import imageio\n",
    "import os\n",
    "from project.utils import labels2binary, kernel, seg_weights_2D, reindex_cell_labels, tracking_weights, rangescale\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "import skimage.morphology as morph\n",
    "from skimage.filters import sobel, gaussian\n",
    "from skimage.measure import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_weights_1(seg, sigma_gaussian = 0.8, n_rounds_gaussian=50, quant_filt = 0.85, final_power = 6):\n",
    "    '''\n",
    "    Custom Weights Function\n",
    "    ______________________________________________________________________________\n",
    "    Function to generate weights that highlight boarders between neighboring cells \n",
    "    Based principally on Sobel filter, gaussian blur and filtering high values\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seg : 2D array\n",
    "        Tracking output mask.\n",
    "    sigma_gaussian : float, optional\n",
    "        Value controlling gaussian blur intensity\n",
    "    n_rounds_gaussian : int, optional\n",
    "        Number of times we iteratively apply gaussian blur\n",
    "    quant_filt : float, optional\n",
    "        Quantile used to filter high intensity value\n",
    "    final_power : float, optional\n",
    "        power to elevate final results to increase contrasts\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    weights : 2D array\n",
    "        Tracking weights map.\n",
    "\n",
    "    '''\n",
    "    # First Sobel filtering to make cell boarders appear\n",
    "    sob_s = sobel(seg)\n",
    "    \n",
    "    # First we apply multiple rounds of gaussian blur\n",
    "    for i in range(n_rounds_gaussian):\n",
    "        sob_s += gaussian(sob_s, sigma=sigma_gaussian, preserve_range=True)\n",
    "\n",
    "    # Second, we only keep highest values (tend to overrepresent intersection between cells)\n",
    "    quant_threshold = np.quantile(sob_s[sob_s > 0], q=quant_filt)\n",
    "    sob_s[sob_s < quant_threshold] = 0\n",
    "    # We give pixel inside cells a minimum value\n",
    "    cell_score = min(sob_s[sob_s > 0])\n",
    "    sob_s[seg == 1] += cell_score\n",
    "\n",
    "    # We reverse the image and do similar filtering : This allow to improve signal on pixels between cells\n",
    "    sob_s[sob_s > 0] = 1/sob_s[sob_s > 0]\n",
    "    quant_threshold = np.quantile(sob_s[sob_s > 0], q=quant_filt)\n",
    "    sob_s[sob_s > quant_threshold] = 0\n",
    "    cell_score = min(sob_s[sob_s > 0])\n",
    "    sob_s[seg == 1] += cell_score\n",
    "    \n",
    "    # We reverse again to the original \n",
    "    sob_s[sob_s > 0] = 1/sob_s[sob_s > 0]\n",
    "\n",
    "    # We expend to a power to exagerate differences \n",
    "    sob_s = sob_s**final_power\n",
    "    \n",
    "    # Normalize between 0 and 255\n",
    "    sob_s = (sob_s - np.min(sob_s))/(np.max(sob_s) - np.min(sob_s)) * 255\n",
    "\n",
    "    return(sob_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUILD TRAINING SET FOR CELL TRACING (FROM MANUAL ANNOTATIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hereafter, we load our manually curated annotation of cell tracking and we build Delta-compatible training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File and folders used \n",
    "cell_img_file = \"data/_fullmovie_images.tif\"\n",
    "cell_seg_file = \"data/_fullmovie_segmentation.tif\"\n",
    "annot_file = \"data/_cell_tracking_manual_annotations.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load raw images which are also used by Delta model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we load the raw images :\n",
    "_, cell_img = cv2.imreadmulti(cell_img_file, [], cv2.IMREAD_ANYDEPTH)\n",
    "# Create numpy to store final values\n",
    "img = np.zeros((125, cell_img[0].shape[0], cell_img[0].shape[1])).astype('float32')\n",
    "# Get min and max from whole movie to normalize image intensity values\n",
    "max_full_img = np.max(cell_img) ; min_full_img = np.min(cell_img)\n",
    "# iterate over frames\n",
    "for i in range(len(cell_img)):\n",
    "    I = cell_img[i].copy().astype('float32')\n",
    "    I_norm = (I - min_full_img)/(max_full_img - min_full_img) # normalization accross all frames and all images\n",
    "    img[i] = (I_norm.copy()*255).astype('uint8') # to subset : training [0:512, 0:512], testing [1024:1536, 0:512] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load the full segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we load the raw images :\n",
    "_, cell_seg_l = cv2.imreadmulti(cell_seg_file, [], cv2.IMREAD_ANYDEPTH)\n",
    "cell_mask = np.zeros((125, cell_seg_l[0].shape[0], cell_seg_l[0].shape[1]))\n",
    "for f in range(len(cell_seg_l)):\n",
    "    labs = cell_seg_l[f].copy()\n",
    "    mask = labels2binary(labs)\n",
    "    mask = binary_fill_holes(mask).astype(np.uint8)\n",
    "    mask[mask > 0] = 1\n",
    "    cell_mask[f] = mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load our manually annotated cell segmentation and use them as label and as binary mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load curated annotations\n",
    "_, annot_l = cv2.imreadmulti(annot_file, [], cv2.IMREAD_ANYDEPTH)\n",
    "# From manual annotation, get labels and binary mask\n",
    "annot_reidx = np.zeros((125,annot_l[0].shape[0],annot_l[0].shape[1]))\n",
    "for i in range(len(annot_l)):\n",
    "    this_lab = reindex_cell_labels(annot_l[i].copy()).astype('uint16') # we keep labs \n",
    "    # Record annotation movie (contains only annotated tracked cells)\n",
    "    annot_reidx[i] = this_lab.copy()\n",
    "    annot_reidx[i][annot_reidx[i] <= 1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hereafter is the loop that will iterate over curated annotations, to choose pair of frames with identical cell annotations. These annotations were done in a way so that unique labels always refer to single cells accross frames. This only special cases are cell division, where there is one cell at frame t connected with two cells at frame t+1. \n",
    "\n",
    "Once the pair of cells has been detected, all the files necessary for cell tracking are written in their respective folder, as Delta is requiring them to be :\n",
    "- previmg : image at time t-1 (input)\n",
    "- img : image at time t (input)\n",
    "- seg : segmentation binary mask showing only cell of interest at time t-1 (input)\n",
    "- segall : segmentation binary mask showing all cells in images at time t (input)\n",
    "- wei : weights of cells at time time t (weights the loss)\n",
    "- mot_dau : segmentation binary mask showing only cell of interest at time t (output of model)\n",
    "\n",
    "All images have to be centered on a cell of interest with size (256,256) around it. 6 images are therefore produced for each pair of cell accross two time points. The curated training set encompass a total of 1454 x 6 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "frame 32, label 2.0\n",
      "33\n",
      "frame 33, label 2.0\n",
      "34\n",
      "frame 34, label 2.0\n",
      "35\n",
      "frame 35, label 2.0\n",
      "36\n",
      "frame 36, label 2.0\n",
      "37\n",
      "frame 37, label 2.0\n",
      "frame 37, label 3.0\n",
      "38\n",
      "frame 38, label 2.0\n",
      "frame 38, label 3.0\n",
      "39\n",
      "frame 39, label 2.0\n",
      "frame 39, label 3.0\n",
      "40\n",
      "frame 40, label 2.0\n",
      "frame 40, label 3.0\n",
      "41\n",
      "frame 41, label 2.0\n",
      "frame 41, label 3.0\n",
      "frame 41, label 4.0\n",
      "42\n",
      "frame 42, label 2.0\n",
      "frame 42, label 3.0\n",
      "frame 42, label 4.0\n",
      "43\n",
      "frame 43, label 2.0\n",
      "frame 43, label 3.0\n",
      "frame 43, label 4.0\n",
      "44\n",
      "frame 44, label 2.0\n",
      "frame 44, label 3.0\n",
      "frame 44, label 4.0\n",
      "45\n",
      "frame 45, label 2.0\n",
      "46\n",
      "frame 46, label 2.0\n",
      "47\n",
      "frame 47, label 2.0\n",
      "frame 47, label 3.0\n",
      "48\n",
      "frame 48, label 2.0\n",
      "frame 48, label 3.0\n",
      "49\n",
      "frame 49, label 2.0\n",
      "frame 49, label 3.0\n",
      "frame 49, label 4.0\n",
      "50\n",
      "frame 50, label 2.0\n",
      "frame 50, label 3.0\n",
      "frame 50, label 4.0\n",
      "51\n",
      "frame 51, label 2.0\n",
      "frame 51, label 3.0\n",
      "frame 51, label 4.0\n",
      "52\n",
      "frame 52, label 2.0\n",
      "frame 52, label 3.0\n",
      "frame 52, label 4.0\n",
      "53\n",
      "frame 53, label 2.0\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"data/training_tracking_test/\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir) ; os.mkdir(out_dir + \"img\") ; os.mkdir(out_dir + \"previmg\") ; os.mkdir(out_dir + \"seg\")\n",
    "    os.mkdir(out_dir + \"segall\") ; os.mkdir(out_dir + \"wei\") ; os.mkdir(out_dir + \"mot_dau\")\n",
    "    \n",
    "idx=1\n",
    "# Iterate over frames : \n",
    "for f in range(124):\n",
    "    print(f)\n",
    "    \n",
    "    # Iterate over unique cell labels found in frame f in our manually annotated data\n",
    "    uniq_labs = np.unique(annot_reidx[f])\n",
    "    for lab in uniq_labs[uniq_labs != 0]:\n",
    "        if any(np.unique(annot_reidx[f+1]) == lab):\n",
    "            print('frame {0}, label {1}'.format(f, lab))\n",
    "            \n",
    "            # Load cell track manual annotations for frame (t)\n",
    "            anno2work = annot_reidx[f].copy() \n",
    "            # Set current cell label to 1 and every other cell to 0\n",
    "            anno2work[anno2work != lab] = 0 ; anno2work[anno2work == lab] = 1 \n",
    "            \n",
    "            # Load annotation for next time frame (t+1)\n",
    "            anno2work_next = annot_reidx[f+1].copy()\n",
    "            # Set current cell label to 1 and every other cell to 0\n",
    "            anno2work_next[anno2work_next != lab] = 0 ; anno2work_next[anno2work_next == lab] = 1\n",
    "                \n",
    "            # Load the segmentation binary mask of all cells at time t+1 \n",
    "            all_seg_fp1 = cell_mask[f+1].copy()\n",
    "            prev_img = img[f].copy()\n",
    "            curr_img = img[f+1].copy()\n",
    "\n",
    "            ### BUILD IMAGE CENTERED ON CELL OF INTEREST ###\n",
    "            # Get mean pixel position on x and y axis\n",
    "            x_mean = int(np.where(anno2work == 1)[0].mean())\n",
    "            y_mean = int(np.where(anno2work == 1)[1].mean())\n",
    "            # Get coordinates on the main segmentation binary mask\n",
    "            x_start = int(max(x_mean - (256/2), 0))\n",
    "            x_end = int(min(x_mean + (256/2), img[0].shape[0]))\n",
    "            y_start = int(max(y_mean - (256/2), 0))\n",
    "            y_end = int(min(y_mean + (256/2), img[0].shape[1]))\n",
    "            # Hereafter the coordinates we calculate for the (256,256) subset image\n",
    "            x_reform_start = int(abs(min(x_mean - (256/2), 0)))\n",
    "            y_reform_start = int(abs(min(y_mean - (256/2), 0)))\n",
    "            x_shift, y_shift = 0, 0\n",
    "            if x_mean + (256/2) > img[0].shape[0]: \n",
    "                x_shift = int(img[0].shape[0] - (x_mean + (256/2)))\n",
    "            if y_mean + (256/2) > img[0].shape[1]: \n",
    "                y_shift = int(img[0].shape[1] - (y_mean + (256/2)))\n",
    "            x_reform_end = int(abs(min(x_mean + (256/2), 256))) + x_shift + x_reform_start\n",
    "            y_reform_end = int(abs(min(y_mean + (256/2), 256))) + y_shift + y_reform_start\n",
    "\n",
    "            # This is the (256,256) segmentation image that matches the prediction (256,256) image\n",
    "            # Thanks to all coordinates found above we can connect our two images with cell of interest\n",
    "            centered_seg = np.zeros((256,256)) ; centered_seg_next = np.zeros((256,256))\n",
    "            centered_all_seg = np.zeros((256,256)) ;  centered_img = np.zeros((256,256))\n",
    "            centered_prev_img = np.zeros((256,256)) ;\n",
    "            centered_seg[x_reform_start:x_reform_end, y_reform_start:y_reform_end] = anno2work[x_start:x_end,y_start:y_end].copy()\n",
    "            centered_seg_next[x_reform_start:x_reform_end, y_reform_start:y_reform_end] = anno2work_next[x_start:x_end,y_start:y_end].copy()\n",
    "            centered_all_seg[x_reform_start:x_reform_end, y_reform_start:y_reform_end] = all_seg_fp1[x_start:x_end,y_start:y_end].copy()\n",
    "            centered_prev_img[x_reform_start:x_reform_end, y_reform_start:y_reform_end] = prev_img[x_start:x_end,y_start:y_end].copy()\n",
    "            centered_img[x_reform_start:x_reform_end, y_reform_start:y_reform_end] = curr_img[x_start:x_end,y_start:y_end].copy()\n",
    "\n",
    "            # Make sure not to consider cases where 2 cells become 1 cell\n",
    "            # Make sure not to consider 1 cell becoming 0 cell\n",
    "            # One condition to check : if n_cell at t is greater that n_cell at t+1, skip\n",
    "            n_cell_t = len(np.unique(label(centered_seg)))-1\n",
    "            n_cell_tp1 = len(np.unique(label(centered_seg_next)))-1\n",
    "            if n_cell_t > n_cell_tp1:\n",
    "                continue\n",
    "                \n",
    "            # Build weight with custom weight function\n",
    "            wei = custom_weights_1(centered_seg_next.copy())\n",
    "            wei[centered_seg_next == 1] = 100 # add minimal weight to cell of interest\n",
    "            wei[centered_seg_next == 0] = 1\n",
    "            wei_01 = ( wei - np.min(wei) ) / (np.max(wei) - np.min(wei))\n",
    "            wei_01 *= 255\n",
    "            wei_int = np.round(wei_01).astype('uint8')\n",
    "            \n",
    "            # Get output name\n",
    "            out_name = \"Sample0000\" + str(idx) + \".png\"\n",
    "            if idx > 9:\n",
    "                out_name = \"Sample000\" + str(idx) + \".png\"\n",
    "            if idx > 99:\n",
    "                out_name = \"Sample00\" + str(idx) + \".png\"\n",
    "            if idx > 999:\n",
    "                out_name = \"Sample0\" + str(idx) + \".png\"\n",
    "            if idx > 9999:\n",
    "                out_name = \"Sample\" + str(idx) + \".png\"\n",
    "                                  \n",
    "            # Write results in folder \n",
    "            cv2.imwrite(out_dir + \"img/\" + out_name, centered_img)\n",
    "            cv2.imwrite(out_dir + \"previmg/\" + out_name, centered_prev_img)\n",
    "            cv2.imwrite(out_dir + \"mot_dau/\" + out_name, centered_seg_next)\n",
    "            cv2.imwrite(out_dir + \"seg/\" + out_name, centered_seg)\n",
    "            cv2.imwrite(out_dir + \"segall/\" + out_name, centered_all_seg)\n",
    "            cv2.imwrite(out_dir + \"wei/\" + out_name, wei_int)\n",
    "            \n",
    "            idx+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare input data for predictions \n",
    "\n",
    "Write the image / segmentation in the same way they were built for building training set (same normalization on image, same segmentation, etc..). Delta needs output in format type `Position01Channe01Frame00001` for tracking predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'data/input_for_predictions/tracking/'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir) ; \n",
    "if not os.path.exists(outdir + \"img\"):\n",
    "    os.mkdir(outdir + \"img\") ; os.mkdir(outdir + \"seg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "compilation = np.zeros((125,300,300)) # here we generate a \"compilation\" file to give as input\n",
    "for f in range(len(img)):\n",
    "    # Get output name\n",
    "    out_name = \"Position01Channe01Frame0000\" + str(idx) + \".png\"\n",
    "    if idx > 9:\n",
    "        out_name = \"Position01Channe01Frame000\" + str(idx) + \".png\"\n",
    "    if idx > 99:\n",
    "        out_name = \"Position01Channe01Frame00\" + str(idx) + \".png\"\n",
    "        \n",
    "    # Write image in folder : \n",
    "    cv2.imwrite(outdir+\"img/\"+out_name, img[f][0:300, 0:300].copy())\n",
    "    \n",
    "    # Prepare segmentation : \n",
    "    seg_c = mask_all[f][0:300, 0:300].copy()\n",
    "    mask = labels2binary(seg_c)\n",
    "    mask = binary_fill_holes(mask).astype(np.uint8)\n",
    "    mask[mask > 0] = 1\n",
    "    compilation[f] = mask\n",
    "    # Write segmentation : \n",
    "    cv2.imwrite(outdir+\"seg/\"+out_name, mask)\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimwrite('data/full_movie_subsest500.tif', img_sub)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "explore_tif.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "general_python3_env",
   "language": "python",
   "name": "general_python3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
